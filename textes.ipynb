{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'*Anthologie* comme recueil de *textes* \n",
    "\n",
    "Avant toute chose, l'Anthologie est un recueil de textes. Commençons donc par nous intéresser à ceux-ci, et à comprendre comment ils se structurent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "with open('dump_api.json','r') as f:\n",
    "    data = json.loads(f.read()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dump de l'API est désormais contenu dans la variable ```data```. Ses données se structurent comme suit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons facilement vérifier cela en vérifiant la longueur de la liste : nous devrions obtenir 4134 résultats : le nombre d'épigrammes sur la plateforme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"La liste data contient\",len(data), \"entrées.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par nous créer un dataframe ```Pandas``` contenant les valeurs suivantes : \n",
    "\n",
    "- id de l'épigramme \n",
    "- url de l'épigramme \n",
    "- url du texte \n",
    "- langue du texte \n",
    "- texte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['epi_id', 'epi_url', 'text_url', 'text_lang', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "for item in data:\n",
    "    texts = item['texts']\n",
    "    for text in texts:\n",
    "        df = pd.concat([df, pd.DataFrame({\n",
    "            'epi_id': [item['id']],\n",
    "            'epi_url': [item['url']],\n",
    "            'text_url': [text['url']],\n",
    "            'text_lang': [text['language']],\n",
    "            'text': [text['text']]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons normaliser quelque peu les textes avant de nous plonger dans une analyse de ceux-ci. Commençons par enlever les sauts de ligne et la ponctuation. La ponctuation pourrait être intéressante pour certaines analyses mais je ne m'y attarderai pas ici. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "liste_ponctuation = [',', ';', ':', '.', '·', '!','?', '(', ')', '[', ']', '–', '«', '»']\n",
    "liste_sauts = ['\\n', '\\r', '-', '\\’', '\\'']\n",
    "\n",
    "def normalized(texte): \n",
    "    for caractere in liste_ponctuation:\n",
    "        texte = texte.replace(caractere, '')\n",
    "    for saut in liste_sauts:\n",
    "        texte = texte.replace(saut, ' ')\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(normalized).str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De là, nous pouvons facilement compter le nombre de textes en grec, en anglais, italien, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces données nous permettent de faire notre première visualisation ! Voyons, sous forme de tarte, la répartition des différentes langues au sein des textes de l'AG : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "ax = df['text_lang'].value_counts().plot(kind='pie')\n",
    "ax.set_title(\"Distribution des langues des textes de l'AGr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons également compter le nombre de caractères et le nombre de mots dans chacun des textes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "df['len'] = df['text'].str.len()\n",
    "df['words'] = df['text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['epi_id', 'epi_url', 'text_url', 'text_lang', 'text', 'len', 'words']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons le nombre total de caractère pour chacune des langues : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "sum_len = df.groupby('text_lang')['len'].sum()\n",
    "sum_words = df.groupby('text_lang')['words'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum_len)\n",
    "print(sum_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "ax1 = sum_len.plot(kind='pie')\n",
    "ax.set_title(\"Nombre de caractère par langues au sein des textes de l'AGr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "ax1 = sum_words.plot(kind='pie')\n",
    "ax.set_title(\"Nombre de mots par langues au sein des textes de l'AGr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourrait également calculer le nombre moyen de caractères et de mots par épigramme en fonction des langues : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_len = df.groupby('text_lang')['len'].mean()\n",
    "print(mean_len)\n",
    "\n",
    "mean_word = df.groupby('text_lang')['words'].mean()\n",
    "print(mean_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "ax = mean_len.plot(kind='bar')\n",
    "ax.set_title(\"Nombre moye de caractère par épigramme au sein de l'AGr selon les langues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "ax = mean_word.plot(kind='bar')\n",
    "ax.set_title(\"Nombre moye de mots par épigramme au sein de l'AGr selon les langues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Éditer les Méta-Données",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
